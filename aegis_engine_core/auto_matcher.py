"""
Aegis Engine - Auto Parameter Matcher
ì›ë³¸ ìŒì›ê³¼ MIDI í•©ì„± ê²°ê³¼ë¥¼ ë¹„êµí•´ì„œ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ìë™ íƒìƒ‰
"""

import numpy as np
import librosa
import io
import tempfile
from aegis_engine_core.synthesizer import synthesize_midi


def _calculate_similarity(original_audio_path, synthesized_wav_data, sample_rate=44100):
    """
    ì›ë³¸ ìŒì›ê³¼ í•©ì„±ëœ WAVì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°

    Args:
        original_audio_path: ì›ë³¸ ìŒì› íŒŒì¼ ê²½ë¡œ
        synthesized_wav_data: í•©ì„±ëœ WAV ë°”ì´íŠ¸ ë°ì´í„°
        sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸

    Returns:
        float: ìœ ì‚¬ë„ ìŠ¤ì½”ì–´ (0.0~1.0, ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
    """
    try:
        # ì›ë³¸ ìŒì› ë¡œë“œ
        y_orig, _ = librosa.load(original_audio_path, sr=sample_rate, duration=30)

        # í•©ì„±ëœ WAVë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ ë¡œë“œ
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            tmp.write(synthesized_wav_data)
            tmp_path = tmp.name

        y_synth, _ = librosa.load(tmp_path, sr=sample_rate)

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        import os
        try:
            os.unlink(tmp_path)
        except:
            pass

        # ê¸¸ì´ ë§ì¶”ê¸° (ì§§ì€ ìª½ì— ë§ì¶¤)
        min_len = min(len(y_orig), len(y_synth))
        y_orig = y_orig[:min_len]
        y_synth = y_synth[:min_len]

        if min_len < sample_rate * 0.5:  # 0.5ì´ˆ ë¯¸ë§Œì´ë©´ ë„ˆë¬´ ì§§ìŒ
            return 0.0

        # 1. Spectral Similarity (Mel Spectrogram)
        mel_orig = librosa.feature.melspectrogram(y=y_orig, sr=sample_rate, n_mels=128)
        mel_synth = librosa.feature.melspectrogram(y=y_synth, sr=sample_rate, n_mels=128)

        # ê¸¸ì´ ë§ì¶”ê¸°
        min_frames = min(mel_orig.shape[1], mel_synth.shape[1])
        mel_orig = mel_orig[:, :min_frames]
        mel_synth = mel_synth[:, :min_frames]

        # Cosine similarity
        mel_orig_flat = mel_orig.flatten()
        mel_synth_flat = mel_synth.flatten()
        spectral_sim = np.dot(mel_orig_flat, mel_synth_flat) / (
            np.linalg.norm(mel_orig_flat) * np.linalg.norm(mel_synth_flat) + 1e-8
        )

        # 2. Chroma Similarity (Pitch content)
        chroma_orig = librosa.feature.chroma_cqt(y=y_orig, sr=sample_rate)
        chroma_synth = librosa.feature.chroma_cqt(y=y_synth, sr=sample_rate)

        # ê¸¸ì´ ë§ì¶”ê¸°
        min_frames = min(chroma_orig.shape[1], chroma_synth.shape[1])
        chroma_orig = chroma_orig[:, :min_frames]
        chroma_synth = chroma_synth[:, :min_frames]

        chroma_orig_flat = chroma_orig.flatten()
        chroma_synth_flat = chroma_synth.flatten()
        chroma_sim = np.dot(chroma_orig_flat, chroma_synth_flat) / (
            np.linalg.norm(chroma_orig_flat) * np.linalg.norm(chroma_synth_flat) + 1e-8
        )

        # ìµœì¢… ìŠ¤ì½”ì–´: ê°€ì¤‘ í‰ê·  (Chromaê°€ í”¼ì¹˜ ì •í™•ë„ì— ë” ì¤‘ìš”)
        final_score = 0.4 * spectral_sim + 0.6 * chroma_sim

        return max(0.0, min(1.0, final_score))  # 0~1ë¡œ í´ë¦¬í•‘

    except Exception as e:
        print(f"[AutoMatcher] ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0


def auto_match_parameters(original_audio_path, engine, raw_data, sample_rate=44100, progress_callback=None):
    """
    ì›ë³¸ ìŒì›ê³¼ MIDIë¥¼ ë¹„êµí•´ì„œ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ìë™ íƒìƒ‰

    Coarse-to-Fine Grid Search:
    - 1ë‹¨ê³„: ë„“ì€ ê°„ê²©ìœ¼ë¡œ ë¹ ë¥´ê²Œ íƒìƒ‰
    - 2ë‹¨ê³„: ìµœì ì  ì£¼ë³€ì„ ì„¸ë°€í•˜ê²Œ íƒìƒ‰

    Args:
        original_audio_path: ì›ë³¸ ìŒì› íŒŒì¼ ê²½ë¡œ
        engine: AegisEngine ì¸ìŠ¤í„´ìŠ¤
        raw_data: engine.audio_to_midi()ì˜ ê²°ê³¼ (ìºì‹œëœ ë¶„ì„ ë°ì´í„°)
        sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸
        progress_callback: ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ (optional)

    Returns:
        dict: {
            'confidence_threshold': float,
            'min_note_duration_ms': int,
            'sustain_ms': int,
            'score': float  # ìœ ì‚¬ë„ ìŠ¤ì½”ì–´ (0.0~1.0)
        }
    """
    print("[AutoMatcher] ğŸ” ìë™ íŒŒë¼ë¯¸í„° ë§¤ì¹­ ì‹œì‘...")

    # === 1ë‹¨ê³„: Coarse Search (ë„“ì€ ê°„ê²©) ===
    coarse_grid = {
        'confidence_threshold': [0.2, 0.4, 0.6],
        'min_note_duration_ms': [50, 150, 250],
        'sustain_ms': [100, 300, 500]
    }

    best_score = -1.0
    best_params = None
    total_iterations = (
        len(coarse_grid['confidence_threshold']) *
        len(coarse_grid['min_note_duration_ms']) *
        len(coarse_grid['sustain_ms'])
    )
    current_iteration = 0

    print(f"[AutoMatcher] 1ë‹¨ê³„: Coarse Grid Search ({total_iterations}ê°œ ì¡°í•©)...")

    for conf in coarse_grid['confidence_threshold']:
        for min_dur in coarse_grid['min_note_duration_ms']:
            for sustain in coarse_grid['sustain_ms']:
                current_iteration += 1

                if progress_callback:
                    progress = current_iteration / total_iterations
                    progress_callback(progress, f"íƒìƒ‰ ì¤‘... ({current_iteration}/{total_iterations})")

                try:
                    # MIDI ìƒì„±
                    midi_buffer = io.BytesIO()
                    engine.extract_events(
                        raw_data,
                        midi_buffer,
                        confidence_threshold=conf,
                        min_note_duration_ms=min_dur,
                        sustain_ms=sustain,
                        midi_program=27  # ê¸°ë³¸ ê¸°íƒ€ íŒ¨ì¹˜
                    )

                    midi_buffer.seek(0)
                    midi_data = midi_buffer.read()

                    if len(midi_data) < 100:  # ë„ˆë¬´ ì‘ìœ¼ë©´ ë¹ˆ MIDI
                        continue

                    # MIDI â†’ WAV í•©ì„±
                    wav_data = synthesize_midi(midi_data, sample_rate=sample_rate)
                    if not wav_data:
                        continue

                    # ìœ ì‚¬ë„ ê³„ì‚°
                    score = _calculate_similarity(original_audio_path, wav_data, sample_rate)

                    print(f"  conf={conf:.1f}, dur={min_dur}, sus={sustain} â†’ score={score:.3f}")

                    if score > best_score:
                        best_score = score
                        best_params = {
                            'confidence_threshold': conf,
                            'min_note_duration_ms': min_dur,
                            'sustain_ms': sustain
                        }

                except Exception as e:
                    print(f"  [AutoMatcher] ì¡°í•© ì‹¤íŒ¨ (conf={conf}, dur={min_dur}, sus={sustain}): {e}")
                    continue

    if not best_params:
        print("[AutoMatcher] âŒ ìœ íš¨í•œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    print(f"[AutoMatcher] 1ë‹¨ê³„ ìµœì ê°’: {best_params}, score={best_score:.3f}")

    # === 2ë‹¨ê³„: Fine Search (ìµœì ì  ì£¼ë³€ ì„¸ë°€ íƒìƒ‰) ===
    fine_grid = {
        'confidence_threshold': [
            max(0.1, best_params['confidence_threshold'] - 0.1),
            best_params['confidence_threshold'],
            min(0.9, best_params['confidence_threshold'] + 0.1)
        ],
        'min_note_duration_ms': [
            max(10, best_params['min_note_duration_ms'] - 50),
            best_params['min_note_duration_ms'],
            min(500, best_params['min_note_duration_ms'] + 50)
        ],
        'sustain_ms': [
            max(0, best_params['sustain_ms'] - 100),
            best_params['sustain_ms'],
            min(1000, best_params['sustain_ms'] + 100)
        ]
    }

    total_iterations = (
        len(fine_grid['confidence_threshold']) *
        len(fine_grid['min_note_duration_ms']) *
        len(fine_grid['sustain_ms'])
    )
    current_iteration = 0

    print(f"[AutoMatcher] 2ë‹¨ê³„: Fine Grid Search ({total_iterations}ê°œ ì¡°í•©)...")

    for conf in fine_grid['confidence_threshold']:
        for min_dur in fine_grid['min_note_duration_ms']:
            for sustain in fine_grid['sustain_ms']:
                current_iteration += 1

                if progress_callback:
                    progress = current_iteration / total_iterations
                    progress_callback(progress, f"ì„¸ë°€ íƒìƒ‰ ì¤‘... ({current_iteration}/{total_iterations})")

                try:
                    midi_buffer = io.BytesIO()
                    engine.extract_events(
                        raw_data,
                        midi_buffer,
                        confidence_threshold=conf,
                        min_note_duration_ms=int(min_dur),
                        sustain_ms=int(sustain),
                        midi_program=27
                    )

                    midi_buffer.seek(0)
                    midi_data = midi_buffer.read()

                    if len(midi_data) < 100:
                        continue

                    wav_data = synthesize_midi(midi_data, sample_rate=sample_rate)
                    if not wav_data:
                        continue

                    score = _calculate_similarity(original_audio_path, wav_data, sample_rate)

                    print(f"  conf={conf:.2f}, dur={min_dur}, sus={sustain} â†’ score={score:.3f}")

                    if score > best_score:
                        best_score = score
                        best_params = {
                            'confidence_threshold': conf,
                            'min_note_duration_ms': int(min_dur),
                            'sustain_ms': int(sustain)
                        }

                except Exception as e:
                    print(f"  [AutoMatcher] ì¡°í•© ì‹¤íŒ¨: {e}")
                    continue

    print(f"[AutoMatcher] âœ… ìµœì¢… ìµœì ê°’: {best_params}, score={best_score:.3f}")

    return {
        **best_params,
        'score': best_score
    }
